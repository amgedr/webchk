#!/usr/bin/env python3

"""
Get HTTP response codes and headers of URLs.

Homepage: http://codehill.com/projects/webchk

Usage:
  webchk [-al] URL... [-o <file>]
  webchk [-al] -i <file> [-o <file>]
  webchk -h, --help
  webchk -v, --version

Options:
  -i <file>, --input <file>     Read input from a file.
  -o <file>, --output <file>    Save output to a file.
  -a, --all                     Display the HTTP header.
  -l, --list                    Print URLs without checking them.
  -h, --help                    Show this
  -v, --version                 Print the version number
"""

import os
import sys
import socket
from docopt import docopt
import http.client
from urllib.parse import urlparse
import xml.etree.ElementTree as etree

version = "webchk 0.1"
arguments = docopt(__doc__, version=version, help=True)


def main():
    try:
        urls_list = []

        # if an input file is provided, place its content in urls_list
        if arguments["--input"]:
            # check if the file exists.
            if os.path.isfile(arguments["--input"]):
                # read all non-empty lines for the input file
                urls_list = filter(
                    None, (u.rstrip() for u in open(arguments["--input"])))
        else:
            print("Error: The specified input file does not exists.")

        # if any URLs were provided in the command-line
        if arguments["URL"]:
            urls_list.extend(arguments["URL"])

        if arguments["--output"]:
            sys.stdout = open(arguments["--output"], "w")

        for u in urls_list:
            http_get(u, 0)

        sys.stdout.close()

    except (KeyboardInterrupt, SystemExit):
        print("\r  \nPocess cancelled by user")
        sys.exit()

def http_get(url, level):
    try:
        loc = urlparse(url)

        # if the scheme (http, https ...) is not available urlparse wont work
        if loc.netloc == "":
            url = "http://" + url
            loc = urlparse(url)

        if arguments["--list"]:
            print("{}{}".format("  " * level, loc.geturl()))
            return

        conn = http.client.HTTPConnection(loc.netloc, port=loc.port)
        if loc.path.endswith(".xml"):
            conn.request("GET", loc.path)   # download the contents of sitemap
            resp = conn.getresponse()

            print("{}{} - {} {}".format(
                "  " * level, url, resp.status, resp.reason))

            if arguments["--all"]:
                for i, v in resp.getheaders():
                    print("{}{}: {}".format("  " * (level + 1), i, v))

            data = resp.read()  # read the contents of the XML file
            rootxml = etree.fromstring(data)

            for i in rootxml:
                for j in i:
                    if j.tag.endswith("loc"):  # get the <loc> tag's contents
                        http_get(j.text.strip(), level + 1)

        else:
            conn.request("HEAD", loc.path)
            resp = conn.getresponse()
            print("{}{} - {} {}".format(
                    "  " * level, url, resp.status, resp.reason))

            if arguments["--all"]:
                for i, v in resp.getheaders():
                    print("{}{}: {}".format("  " * (level + 1), i, v))

            # if response code is 301 Moved Permanently or 302 Redirected
            if resp.status == 301 or resp.status == 302:
                # get the URL being redirected to
                http_get(resp.getheader("Location"), level + 1)

    except (KeyboardInterrupt, SystemExit):
        raise
        #print("Process cancelled by user")
        #sys.exit()
    except socket.gaierror:
        print(url, "- Could not resolve name")
    except BaseException as err:
        print("{} - Error: {}".format(url, err))


if __name__ == "__main__":
    main()
